{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "There is no dataset in tfds called SketchRNN. There is the \"quickdraw_bitmap\" dataset (SketchRNN is a network by the Google Magenta team that was trained on this data), which was too big for me to handle on my laptop, so I'll skip this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10\n",
    "\n",
    "Download the mentioned file. I put it in /15-data/jsb/ and unzipped it with the command:\n",
    "\n",
    "    tar -xvzf jsb_chorales.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "import os\n",
    "\n",
    "dataset_path = os.path.join(\"15-data\", \"jsb\")\n",
    "train_path = os.path.join(dataset_path, \"train\")\n",
    "valid_path = os.path.join(dataset_path, \"valid\")\n",
    "test_path = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "train_files = [train_path + os.path.sep + f for f in os.listdir(train_path)]\n",
    "valid_files = [valid_path + os.path.sep + f for f in os.listdir(valid_path)]\n",
    "test_files = [test_path + os.path.sep + f for f in os.listdir(test_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the csv's\n",
    "\n",
    "train_data = []\n",
    "valid_data = []\n",
    "test_data = []\n",
    "\n",
    "for file in train_files:\n",
    "    train_data.append(pd.read_csv(file).to_numpy())\n",
    "for file in valid_files:\n",
    "    valid_data.append(pd.read_csv(file).to_numpy())\n",
    "for file in test_files:\n",
    "    test_data.append(pd.read_csv(file).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of samples is 640\n"
     ]
    }
   ],
   "source": [
    "max_train_length = max(len(l) for l in train_data)\n",
    "max_valid_length = max(len(l) for l in valid_data)\n",
    "max_test_length = max(len(l) for l in test_data)\n",
    "\n",
    "max_length = max((max_train_length, max_valid_length, max_test_length))\n",
    "\n",
    "print(\"maximum length of samples is {}\".format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we build the train/valid/test sets. because the samples are of non-uniform length we'll use a masking layer\n",
    "# therefore, we prepend non-maximum-length samples with zeros.\n",
    "\n",
    "def build_set(data):\n",
    "    n_samples = len(data)\n",
    "    set = np.empty((n_samples, max_length, 4))\n",
    "    set[:, :, :] = -1.0   # padding value\n",
    "    for idx, sample in enumerate(data):\n",
    "        set[idx, -1*len(sample):, :] = sample / 128.0   # max MIDI\n",
    "    return set\n",
    "\n",
    "X_train = build_set(train_data)\n",
    "X_valid = build_set(valid_data)\n",
    "X_test = build_set(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll be trying to predict one timestep ahead\n",
    "\n",
    "def build_target(X):\n",
    "    target = np.zeros(X.shape)\n",
    "    target[:, :-1, :] = X[:, 1:, :]\n",
    "    return target\n",
    "\n",
    "Y_train = build_target(X_train)\n",
    "Y_valid = build_target(X_valid)\n",
    "Y_test = build_target(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the last timestep, we have no prediction there\n",
    "\n",
    "X_train, Y_train = X_train[:, :-1, :], Y_train[:, :-1, :]\n",
    "X_valid, Y_valid = X_valid[:, :-1, :], Y_valid[:, :-1, :]\n",
    "X_test, Y_test = X_test[:, :-1, :], Y_test[:, :-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(100, return_sequences=True),\n",
    "    keras.layers.GRU(100, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(4))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_error(Y_true, Y_pred):\n",
    "    return tf.math.reduce_sum(tf.math.abs(Y_true[:, -1] - Y_pred[:, -1]))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[last_time_step_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 229 samples, validate on 76 samples\n",
      "Epoch 1/50\n",
      "229/229 [==============================] - 29s 126ms/sample - loss: 0.0037 - last_time_step_error: 1.8852 - val_loss: 0.0039 - val_last_time_step_error: 1.6727\n",
      "Epoch 2/50\n",
      "229/229 [==============================] - 31s 133ms/sample - loss: 0.0036 - last_time_step_error: 1.9313 - val_loss: 0.0039 - val_last_time_step_error: 1.6742\n",
      "Epoch 3/50\n",
      "229/229 [==============================] - 17s 74ms/sample - loss: 0.0036 - last_time_step_error: 1.8492 - val_loss: 0.0039 - val_last_time_step_error: 1.6715\n",
      "Epoch 4/50\n",
      "229/229 [==============================] - 27s 118ms/sample - loss: 0.0036 - last_time_step_error: 1.8840 - val_loss: 0.0038 - val_last_time_step_error: 1.6315\n",
      "Epoch 5/50\n",
      "229/229 [==============================] - 35s 151ms/sample - loss: 0.0036 - last_time_step_error: 1.7998 - val_loss: 0.0038 - val_last_time_step_error: 1.6380\n",
      "Epoch 6/50\n",
      "229/229 [==============================] - 25s 108ms/sample - loss: 0.0036 - last_time_step_error: 1.8165 - val_loss: 0.0038 - val_last_time_step_error: 1.6134\n",
      "Epoch 7/50\n",
      "229/229 [==============================] - 14s 61ms/sample - loss: 0.0036 - last_time_step_error: 1.8256 - val_loss: 0.0038 - val_last_time_step_error: 1.5877\n",
      "Epoch 8/50\n",
      "229/229 [==============================] - 21s 93ms/sample - loss: 0.0036 - last_time_step_error: 1.7447 - val_loss: 0.0038 - val_last_time_step_error: 1.5786\n",
      "Epoch 9/50\n",
      "229/229 [==============================] - 19s 84ms/sample - loss: 0.0036 - last_time_step_error: 1.7642 - val_loss: 0.0038 - val_last_time_step_error: 1.5457\n",
      "Epoch 10/50\n",
      "229/229 [==============================] - 23s 102ms/sample - loss: 0.0036 - last_time_step_error: 1.7021 - val_loss: 0.0038 - val_last_time_step_error: 1.5495\n",
      "Epoch 11/50\n",
      "229/229 [==============================] - 28s 120ms/sample - loss: 0.0036 - last_time_step_error: 1.7108 - val_loss: 0.0038 - val_last_time_step_error: 1.5214\n",
      "Epoch 12/50\n",
      "229/229 [==============================] - 18s 78ms/sample - loss: 0.0036 - last_time_step_error: 1.6874 - val_loss: 0.0038 - val_last_time_step_error: 1.4878\n",
      "Epoch 13/50\n",
      "229/229 [==============================] - 17s 74ms/sample - loss: 0.0036 - last_time_step_error: 1.6278 - val_loss: 0.0038 - val_last_time_step_error: 1.4916\n",
      "Epoch 14/50\n",
      "229/229 [==============================] - 14s 62ms/sample - loss: 0.0036 - last_time_step_error: 1.6312 - val_loss: 0.0038 - val_last_time_step_error: 1.4704\n",
      "Epoch 15/50\n",
      "229/229 [==============================] - 16s 69ms/sample - loss: 0.0036 - last_time_step_error: 1.5890 - val_loss: 0.0038 - val_last_time_step_error: 1.4730\n",
      "Epoch 16/50\n",
      "229/229 [==============================] - 13s 58ms/sample - loss: 0.0036 - last_time_step_error: 1.6319 - val_loss: 0.0038 - val_last_time_step_error: 1.4452\n",
      "Epoch 17/50\n",
      "229/229 [==============================] - 15s 65ms/sample - loss: 0.0036 - last_time_step_error: 1.5498 - val_loss: 0.0038 - val_last_time_step_error: 1.4147\n",
      "Epoch 18/50\n",
      "229/229 [==============================] - 17s 74ms/sample - loss: 0.0036 - last_time_step_error: 1.5561 - val_loss: 0.0038 - val_last_time_step_error: 1.4075\n",
      "Epoch 19/50\n",
      "229/229 [==============================] - 17s 74ms/sample - loss: 0.0036 - last_time_step_error: 1.5025 - val_loss: 0.0038 - val_last_time_step_error: 1.3776\n",
      "Epoch 20/50\n",
      "229/229 [==============================] - 16s 68ms/sample - loss: 0.0036 - last_time_step_error: 1.4965 - val_loss: 0.0038 - val_last_time_step_error: 1.4101\n",
      "Epoch 21/50\n",
      "229/229 [==============================] - 30s 132ms/sample - loss: 0.0036 - last_time_step_error: 1.5030 - val_loss: 0.0037 - val_last_time_step_error: 1.3723\n",
      "Epoch 22/50\n",
      "229/229 [==============================] - 30s 133ms/sample - loss: 0.0036 - last_time_step_error: 1.4832 - val_loss: 0.0037 - val_last_time_step_error: 1.3374\n",
      "Epoch 23/50\n",
      "229/229 [==============================] - 30s 130ms/sample - loss: 0.0036 - last_time_step_error: 1.4285 - val_loss: 0.0037 - val_last_time_step_error: 1.3136\n",
      "Epoch 24/50\n",
      "229/229 [==============================] - 31s 136ms/sample - loss: 0.0036 - last_time_step_error: 1.4293 - val_loss: 0.0037 - val_last_time_step_error: 1.3508\n",
      "Epoch 25/50\n",
      "229/229 [==============================] - 31s 135ms/sample - loss: 0.0036 - last_time_step_error: 1.4187 - val_loss: 0.0037 - val_last_time_step_error: 1.2843\n",
      "Epoch 26/50\n",
      "229/229 [==============================] - 30s 132ms/sample - loss: 0.0036 - last_time_step_error: 1.3891 - val_loss: 0.0037 - val_last_time_step_error: 1.2952\n",
      "Epoch 27/50\n",
      "229/229 [==============================] - 31s 137ms/sample - loss: 0.0036 - last_time_step_error: 1.3587 - val_loss: 0.0037 - val_last_time_step_error: 1.2413\n",
      "Epoch 28/50\n",
      "229/229 [==============================] - 33s 144ms/sample - loss: 0.0036 - last_time_step_error: 1.3458 - val_loss: 0.0037 - val_last_time_step_error: 1.2472\n",
      "Epoch 29/50\n",
      "229/229 [==============================] - 37s 160ms/sample - loss: 0.0036 - last_time_step_error: 1.3442 - val_loss: 0.0037 - val_last_time_step_error: 1.2927\n",
      "Epoch 30/50\n",
      "229/229 [==============================] - 32s 138ms/sample - loss: 0.0036 - last_time_step_error: 1.3193 - val_loss: 0.0037 - val_last_time_step_error: 1.2253\n",
      "Epoch 31/50\n",
      "229/229 [==============================] - 32s 141ms/sample - loss: 0.0036 - last_time_step_error: 1.2994 - val_loss: 0.0037 - val_last_time_step_error: 1.1786\n",
      "Epoch 32/50\n",
      "229/229 [==============================] - 32s 141ms/sample - loss: 0.0036 - last_time_step_error: 1.2849 - val_loss: 0.0037 - val_last_time_step_error: 1.1506\n",
      "Epoch 33/50\n",
      "229/229 [==============================] - 31s 134ms/sample - loss: 0.0035 - last_time_step_error: 1.2469 - val_loss: 0.0037 - val_last_time_step_error: 1.1436\n",
      "Epoch 34/50\n",
      "229/229 [==============================] - 34s 148ms/sample - loss: 0.0035 - last_time_step_error: 1.2390 - val_loss: 0.0037 - val_last_time_step_error: 1.1250\n",
      "Epoch 35/50\n",
      "229/229 [==============================] - 33s 145ms/sample - loss: 0.0035 - last_time_step_error: 1.2484 - val_loss: 0.0037 - val_last_time_step_error: 1.0595\n",
      "Epoch 36/50\n",
      "229/229 [==============================] - 30s 133ms/sample - loss: 0.0035 - last_time_step_error: 1.1404 - val_loss: 0.0037 - val_last_time_step_error: 1.1571\n",
      "Epoch 37/50\n",
      "229/229 [==============================] - 16s 71ms/sample - loss: 0.0035 - last_time_step_error: 1.2003 - val_loss: 0.0037 - val_last_time_step_error: 1.0211\n",
      "Epoch 38/50\n",
      "229/229 [==============================] - 16s 71ms/sample - loss: 0.0035 - last_time_step_error: 1.1224 - val_loss: 0.0037 - val_last_time_step_error: 1.0721\n",
      "Epoch 39/50\n",
      "229/229 [==============================] - 17s 73ms/sample - loss: 0.0035 - last_time_step_error: 1.1127 - val_loss: 0.0037 - val_last_time_step_error: 0.9951\n",
      "Epoch 40/50\n",
      "229/229 [==============================] - 18s 80ms/sample - loss: 0.0035 - last_time_step_error: 1.0590 - val_loss: 0.0037 - val_last_time_step_error: 1.0205\n",
      "Epoch 41/50\n",
      "229/229 [==============================] - 24s 103ms/sample - loss: 0.0035 - last_time_step_error: 1.0756 - val_loss: 0.0037 - val_last_time_step_error: 0.9514\n",
      "Epoch 42/50\n",
      "229/229 [==============================] - 25s 110ms/sample - loss: 0.0035 - last_time_step_error: 1.0686 - val_loss: 0.0037 - val_last_time_step_error: 0.9178\n",
      "Epoch 43/50\n",
      "229/229 [==============================] - 38s 165ms/sample - loss: 0.0035 - last_time_step_error: 0.9997 - val_loss: 0.0037 - val_last_time_step_error: 0.9401\n",
      "Epoch 44/50\n",
      "229/229 [==============================] - 19s 81ms/sample - loss: 0.0035 - last_time_step_error: 0.9655 - val_loss: 0.0037 - val_last_time_step_error: 0.8854\n",
      "Epoch 45/50\n",
      "229/229 [==============================] - 20s 88ms/sample - loss: 0.0035 - last_time_step_error: 0.9665 - val_loss: 0.0037 - val_last_time_step_error: 0.8454\n",
      "Epoch 46/50\n",
      "229/229 [==============================] - 25s 107ms/sample - loss: 0.0035 - last_time_step_error: 0.9299 - val_loss: 0.0037 - val_last_time_step_error: 0.8426\n",
      "Epoch 47/50\n",
      "229/229 [==============================] - 19s 84ms/sample - loss: 0.0035 - last_time_step_error: 0.8900 - val_loss: 0.0037 - val_last_time_step_error: 0.8396\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 15s 64ms/sample - loss: 0.0035 - last_time_step_error: 0.8590 - val_loss: 0.0037 - val_last_time_step_error: 0.7960\n",
      "Epoch 49/50\n",
      "229/229 [==============================] - 27s 119ms/sample - loss: 0.0035 - last_time_step_error: 0.8366 - val_loss: 0.0037 - val_last_time_step_error: 0.8144\n",
      "Epoch 50/50\n",
      "229/229 [==============================] - 26s 115ms/sample - loss: 0.0035 - last_time_step_error: 0.8141 - val_loss: 0.0037 - val_last_time_step_error: 0.7550\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=50, \n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a metric, we're looking at a sum of absolute differences between the prediction and target vector. We see that the model is training - this would me more fun on a GPU for sure. The network is training and the metric looks to do the right thing. This is enough for me & I'll call it a day, while there could a million things be tweaked for sure. Let's just try a prediction and look at the correct values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.670017, 59.33638 , 56.684753, 43.57272 ],\n",
       "       [62.81531 , 58.861008, 56.104836, 44.497883],\n",
       "       [62.896473, 58.65264 , 55.219753, 44.342564],\n",
       "       [62.676994, 58.227837, 55.19636 , 45.345043],\n",
       "       [63.316914, 58.71766 , 55.280937, 45.42322 ],\n",
       "       [62.310215, 58.345566, 54.967216, 44.695   ],\n",
       "       [62.930794, 58.79892 , 55.094444, 44.06912 ],\n",
       "       [61.078457, 58.00331 , 54.428917, 41.779564],\n",
       "       [61.88028 , 58.522095, 54.872017, 41.169178],\n",
       "       [61.191967, 57.972366, 54.286438, 40.381042],\n",
       "       [61.66104 , 58.18567 , 54.419334, 40.30004 ],\n",
       "       [61.904984, 58.56436 , 54.75032 , 40.337906],\n",
       "       [61.962124, 58.626915, 54.956005, 40.350636],\n",
       "       [61.154655, 57.328278, 53.560703, 39.72917 ],\n",
       "       [61.478954, 57.402466, 52.970367, 39.47121 ],\n",
       "       [61.804436, 58.046852, 53.755157, 40.320908],\n",
       "       [62.068935, 58.161697, 54.0656  , 40.201065],\n",
       "       [61.916653, 58.144226, 53.931763, 39.927032],\n",
       "       [61.902386, 58.206375, 54.06535 , 40.0957  ],\n",
       "       [61.96639 , 58.231995, 54.090157, 39.982372]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[0,-22:-2,:] * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62., 57., 55., 45.],\n",
       "       [62., 57., 54., 45.],\n",
       "       [62., 55., 55., 46.],\n",
       "       [62., 57., 55., 46.],\n",
       "       [62., 58., 55., 43.],\n",
       "       [62., 58., 55., 43.],\n",
       "       [62., 58., 55., 38.],\n",
       "       [62., 58., 55., 38.],\n",
       "       [62., 57., 54., 38.],\n",
       "       [62., 57., 54., 38.],\n",
       "       [62., 58., 55., 38.],\n",
       "       [62., 58., 55., 38.],\n",
       "       [62., 55., 52., 38.],\n",
       "       [62., 55., 52., 38.],\n",
       "       [62., 57., 54., 38.],\n",
       "       [62., 57., 54., 38.],\n",
       "       [62., 57., 54., 38.],\n",
       "       [62., 57., 54., 38.],\n",
       "       [62., 57., 54., 38.],\n",
       "       [62., 57., 54., 38.]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0,-22:-2,:] * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
